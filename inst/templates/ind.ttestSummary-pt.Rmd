---
title: "Resumo do teste t para {{ paste0(paste0('`', dvs, '`'), collapse = ',') }} com `{{ iv }}`"
author: {{ author }} <{{ email }}>
comment: This file is automatically generate by Shiny-Statistic app (https://statistic.geiser.tech/)
         Author - Geiser C. Challco <geiser@usp.br>
         
         Shiny-Statistic is distributed in the hope that it will be useful,
         but WITHOUT ANY WARRANTY; without even the implied warranty of
         MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
         GNU General Public License for more details.
         
         You should have received a copy of the GNU General Public License.
         If not, see <https://www.gnu.org/licenses/>.
output:
  github_document: default
  word_document: default
  html_document: default
  pdf_document:
    keep_tex: true
fontsize: 10pt
---

```{r setup, include=FALSE}
if (!'remotes' %in% rownames(installed.packages())) install.packages('remotes')
if (!"rshinystatistics" %in% rownames(installed.packages())) {
  remotes::install_github("geiser/rshinystatistics")
} else if (packageVersion("rshinystatistics") < "{{ rshinystatistics.version }}") {
  remotes::install_github("geiser/rshinystatistics")
}

wants <- c('ggplot2','ggpubr','rshinystatistics','utils', 'knitr')
has <- wants %in% rownames(installed.packages())
if (any(!has)) install.packages(wants[!has])

library(knitr)
opts_chunk$set(echo = TRUE)

library(utils)
library(ggpubr)
library(ggplot2)
library(rshinystatistics)

defaultW <- getOption("warn")
options(warn = -1)
```

## Dados e R-Scripts

* R-script file: [ind.ttest.R](ind.ttest.R)
{{ paste0(paste0('* Data for ', dvs, ' [data-',dvs,'.csv](data-',dvs,'.csv)'), collapse = '\n') }}

### Definição do identicador, variáveis dependentes e independentes

```{r}
iv <- "{{ iv }}"
wid <- "{{ wid }}"
dvs <- c({{ paste0(paste0('"', dvs, '"'), collapse = ',') }})
ldvs <- as.list(dvs); names(ldvs) <- dvs
dat <- lapply(ldvs, FUN = function(dv) {
  data <- read.csv(paste0("data-",dv,".csv"))
  rownames(data) <- data[["{{ wid }}"]]
  return(data)
})
```

## Validação de Premissas

### Tirando outliers dos dados

```{r}
outliers <- {{ code.outliers }}
rdat <- remove_from_datatable(dat, outliers, wid, "var")
```

### Validação da premissa de normalidade

**Observações**:

Conforme o tamanho da amostra aumenta, os testes paramétricos permanecem válidos mesmo com a violação da premissa de normalidade <sup>[[1](# referências)]</sup>.
De acordo com o teorema central do limite, a distribuição amostral tende a ser normal se a amostra for grande, a partir de (`n > 30`) observações. Portanto, quando realizamos testes paramétricos com grandes amostras, efetuamos a valiação da premissa da normalidade conforme a descrito a seguir:

- Nos casos com tamanho de amostra superior a 30 (`n > 30`), se adotou como nível de significância `p < 0,01` ao invés do classico `p < 0,05`.

- Nos casos com o tamanho maior do que 100 (`n > 100`), o nível de significância foi de `p < 0,001`

- Para amostras com observação `n > 50`, adotamos o teste D'Agostino-Pearson que oferece melhor precisão para amostras maiores <sup>[[2](#referências)]</sup>.

- Para amostras de 'tamanho entre `n > 100` e ` n <= 200`, ignoramos ambos testes (Shapiro e D'Agostino-Pessoas), e nossa validação de normalidade foi baseada apenas na interpretação de gráficos QQ e histogramas porque esses testes tendem a ser muito sensíveis com valores maiores que 200 <sup>[[3](#referências)]</sup>.

- Para amostras com observação maiores de `n> 200` observações, ignoramos a suposição de normalidade com base no teorema central do limite.

#### Aplicando transformações em curvas distorcidas e não simétricas 

{{ code.skewness }}


#### Tirando observações que afetam a normalidade da curva de dados (considerados valores extremos)

```{r}
non.normal <- {{ code.non.normal }}
sdat <- remove_from_datatable(rdat, non.normal, wid, "var")
```


#### Verificação da premissa da normalidade nos grupos definido pela variável independente

```r
normality_test_per_group(sdat, dvs, iv, dv.var = 'var')
```

```{r echo=FALSE}
kdf <- normality_test_per_group(sdat, dvs, iv, dv.var = 'var')
kdf$p <- round(kdf$p, 3)
kdf$p[which(kdf$p < 0.001)] <- '<0.001'
kable(kdf, digits = 3)
```

### Validando premissa de homogeneidade das variâncias

```r
homogeneity_test(sdat, dvs, iv, dv.var = 'var')
```

```{r echo=FALSE}
kdf <- homogeneity_test(sdat, dvs, iv, dv.var = 'var')
kdf$p <- round(kdf$p, 3)
kdf$p[which(kdf$p < 0.001)] <- '<0.001'
kable(kdf, digits = 3)
```

A premissa de homogeneidade pode ser ignorada se usar Welch's teste t (Welch's t-test) (método padrão no rshiny-statistics).


## Computando o teste t e tamanhos de efeito

```r
res <- ind_ttest(sdat, dvs, iv, "{{ alternative }}", {{ var.equal }}, {{ hedges.correction }}, dv.var='var', as.list=T)
(res$t.test)
```

```{r echo=FALSE}
res <- ind_ttest(sdat, dvs, iv, "{{ alternative }}", {{ var.equal }}, {{ hedges.correction }}, dv.var='var', as.list=T)
kdf <- res$t.test[,c(".y.", "group1", "group2", "n1", "n2","statistic", "df", "p", "estimate",
                    "conf.low", "conf.high", "effsize", "magnitude", "p.signif")]
kdf$p <- round(kdf$p, 3)
kdf$p[which(kdf$p < 0.001)] <- '<0.001'
kable(kdf, digits = 3)
```

## Estatística Descritiva e Gráficos dos Testes T 

```r
descriptive_statistics(sdat, dvs, iv, "common", "var")
```

```{r echo=FALSE}
kdf <- descriptive_statistics(sdat, dvs, iv, "common", "var")
cnames <- c("n","mean","median","min","max","q1","q3","sd","se","ci","iqr","mad")
cnames <- unique(c("variable", colnames(kdf)[!colnames(kdf) %in% cnames], "n", "mean", "median","sd","se","ci"))
kdf <- kdf[,cnames]
kable(kdf, digits = 3)
```

{{ ttest.plots  }}


## Relátorio Textual

{{ ttest.text }}

## Referências

<sup>[1]</sup>: Ghasemi, A., & Zahediasl, S. (2012). Normality tests for statistical analysis: a guide for non-statisticians. International journal of endocrinology and metabolism, 10(2), 486.

<sup>[1]</sup>: Miot, H. A. (2017). Assessing normality of data in clinical and experimental trials. J Vasc Bras, 16(2), 88-91.
