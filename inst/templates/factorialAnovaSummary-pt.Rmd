---
title: "Resumo do ANOVA fatorial para {{ paste0(paste0('`', dvs, '`'), collapse = ',') }}"
author: {{ author }} <{{ email }}>
comment: This file is automatically generate by Shiny-Statistic app (https://statistic.geiser.tech/)
         Author - Geiser C. Challco <geiser@usp.br>
         
         Shiny-Statistic is distributed in the hope that it will be useful,
         but WITHOUT ANY WARRANTY; without even the implied warranty of
         MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
         GNU General Public License for more details.
         
         You should have received a copy of the GNU General Public License.
         If not, see <https://www.gnu.org/licenses/>.
output:
  github_document: default
  word_document: default
  html_document: default
  pdf_document:
    keep_tex: true
fontsize: 10pt
---

```{r setup, include=FALSE}
if (!'remotes' %in% rownames(installed.packages())) install.packages('remotes')
if (!"rshinystatistics" %in% rownames(installed.packages())) {
  remotes::install_github("geiser/rshinystatistics")
} else if (packageVersion("rshinystatistics") < "{{ rshinystatistics.version }}") {
  remotes::install_github("geiser/rshinystatistics")
}

wants <- c('ggplot2','ggpubr','rshinystatistics','utils', 'knitr')
has <- wants %in% rownames(installed.packages())
if (any(!has)) install.packages(wants[!has])

library(knitr)
opts_chunk$set(echo = TRUE)

library(utils)
library(ggpubr)
library(ggplot2)
library(rshinystatistics)

defaultW <- getOption("warn")
options(warn = -1)
```

## Dados Inicias e R-Scripts

* R-script file: [factorialAnova.R](factorialAnova.R)
{{ paste0(paste0('* Data for ', dvs, ' [data-',dvs,'.csv](data-',dvs,'.csv)'), collapse = '\n') }}

### Definindo identificador e variáveis dependentes e independentes

```{r}
wid <- "{{ wid }}"
between <- c({{ paste0(paste0('"', between, '"'), collapse = ',') }})
dvs <- c({{ paste0(paste0('"', dvs, '"'), collapse = ',') }})
ldvs <- as.list(dvs); names(ldvs) <- dvs
dat <- lapply(ldvs, FUN = function(dv) {
  data <- read.csv(paste0("data-",dv,".csv"))
  rownames(data) <- data[["{{ wid }}"]]
  return(data)
})
```

## Validação das Premissas

### Tirando ouliers dos dados

```{r}
outliers <- {{ code.outliers }}
rdat <- remove_from_datatable(dat, outliers, wid, "var")
```

### Premissa da Normalidade

**Observações**:

Conforme o tamanho da amostra aumenta, os testes paramétricos permanecem válidos mesmo com a violação da premissa de normalidade <sup>[[1](# referências)]</sup>.
De acordo com o teorema central do limite, a distribuição amostral tende a ser normal se a amostra for grande, a partir de (`n > 30`) observações. Portanto, quando realizamos testes paramétricos com grandes amostras, efetuamos a valiação da premissa da normalidade conforme a descrito a seguir:

- Nos casos com tamanho de amostra superior a 30 (`n > 30`), se adotou como nível de significância `p < 0,01` ao invés do classico `p < 0,05`.

- Nos casos com o tamanho maior do que 100 (`n > 100`), o nível de significância foi de `p < 0,001`

- Para amostras com observação `n > 50`, adotamos o teste D'Agostino-Pearson que oferece melhor precisão para amostras maiores <sup>[[2](#referências)]</sup>.

- Para amostras de 'tamanho entre `n > 100` e ` n <= 200`, ignoramos ambos testes (Shapiro e D'Agostino-Pessoas), e nossa validação de normalidade foi baseada apenas na interpretação de gráficos QQ e histogramas porque esses testes tendem a ser muito sensíveis com valores maiores que 200 <sup>[[3](#referências)]</sup>.

- Para amostras com observação maiores de `n> 200` observações, ignoramos a suposição de normalidade com base no teorema central do limite.


#### Aplicando transformação para lidar com distorsão quando normalidade não é alcançada

{{ code.skewness }}

#### Tirando dados que afeta normalidade (valores extremos)

```{r}
non.normal <- {{ code.non.normal }}
sdat <- remove_from_datatable(rdat, non.normal, wid, "var")
```

#### Validando premissa de normalidade nos resíduos

```r
normality_test_by_res(sdat, dvs, between, dv.var='var')
```

```{r echo=FALSE}
kdf <- normality_test_by_res(sdat, dvs, between, dv.var='var')
kdf$p <- round(kdf$p, 3)
kdf$p[which(kdf$p < 0.001)] <- '<0.001'
kable(kdf, digits = 3)
```

### Premissa de Homogeneidade

```r
normality_test_per_group(sdat, dvs, between, dv.var = 'var')
```

```{r echo=FALSE}
kdf <- normality_test_per_group(sdat, dvs, between, dv.var = 'var')
kdf$p <- round(kdf$p, 3)
kdf$p[which(kdf$p < 0.001)] <- '<0.001'
kable(kdf, digits = 3)
```

### Homogeneity assumption

```r
homogeneity_test(sdat, dvs, between, dv.var='var')
```

```{r echo=FALSE}
kdf <- homogeneity_test(sdat, dvs, between, dv.var='var')
kdf$p <- round(kdf$p, 3)
kdf$p[which(kdf$p < 0.001)] <- '<0.001'
kable(kdf, digits = 3)
```

Homogeneidade pode ser ignorada empregado Wilcox's método (ainda não disponível no rshiny-statistics).

## Computação do ANCOVA e Comparação Parelhada

### teste ANCOVA

```r
aov <- get.anova.test(sdat, dvs, between, type = {{ type }}, effect.size = "{{ effect.size }}", dv.var = "var")
(get.anova.table(aov))
```

```{r echo=FALSE}
aov <- get.anova.test(sdat, dvs, between, type = {{ type }}, effect.size = "{{ effect.size }}", dv.var = "var")
cnames <- c("var", "Effect", "DFn", "DFd", "SSn", "SSd", "F", "p", "{{ effect.size }}", "p.signif")
kdf <- get.anova.table(aov)[,cnames]
kdf$p <- round(kdf$p, 3)
kdf$p[which(kdf$p < 0.001)] <- '<0.001'
kable(kdf, digits = 3)
```

### Resultado da comparação parelhada que apresenta diferenças significativas

```r
pwc <- get.anova.pwc(sdat, dvs, between, p.adjust.method = "{{ p.adjust.method }}", dv.var = "var")
(get.anova.pwc.table(pwc, only.sig = T))
```

```{r echo=FALSE}
pwc <- get.anova.pwc(sdat, dvs, between, p.adjust.method = "{{ p.adjust.method }}", dv.var = "var")
cnames <- c("var", between, "group1", "group2","estimate", "se","df","statistic","p", "p.adj","p.adj.signif")
kdf <- get.anova.pwc.table(pwc, only.sig = T)[,cnames]
kdf$p <- round(kdf$p, 3)
kdf$p[which(kdf$p < 0.001)] <- '<0.001'
kdf$p.adj <- round(kdf$p.adj, 3)
kdf$p.adj[which(kdf$p.adj < 0.001)] <- '<0.001'
kable(kdf, digits = 3)
```

## Médias marginais estimadas e gráficos de ANOVA


```r
get.anova.emmeans.with.ds(pwc, sdat, dvs, between, "common", "var")
```

```{r echo=FALSE}
kdf <- get.anova.emmeans.with.ds(pwc, sdat, dvs, between, "common", "var")
cnames <- c("var",between,"n","emmean","se.emms","conf.low","conf.high","mean","median","sd","ci")
kdf <- kdf[,cnames]
kable(kdf, digits = 3)
```

{{ anova.plots  }}

## Relátorio Textual

{{ anova.text }}

{{ anova.pwc.text }}

## Referências

<sup>[1]</sup>: Ghasemi, A., & Zahediasl, S. (2012). Normality tests for statistical analysis: a guide for non-statisticians. International journal of endocrinology and metabolism, 10(2), 486.

<sup>[1]</sup>: Miot, H. A. (2017). Assessing normality of data in clinical and experimental trials. J Vasc Bras, 16(2), 88-91.


```{r include=FALSE}
options(warn = defaultW)
```
